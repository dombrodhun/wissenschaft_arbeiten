@article{allam2025,
  title = {Text {{Classification}}: {{How Machine Learning Is Revolutionizing Text Categorization}}},
  shorttitle = {Text {{Classification}}},
  author = {Allam, Hesham and Makubvure, Lisa and Gyamfi, Benjamin and Graham, Kwadwo Nyarko and Akinwolere, Kehinde},
  date = {2025-02},
  journaltitle = {Information},
  volume = {16},
  number = {2},
  pages = {130},
  publisher = {Multidisciplinary Digital Publishing Institute},
  issn = {2078-2489},
  doi = {10.3390/info16020130},
  url = {https://www.mdpi.com/2078-2489/16/2/130},
  urldate = {2025-07-27},
  abstract = {The automated classification of texts into predefined categories has become increasingly prominent, driven by the exponential growth of digital documents and the demand for efficient organization. This paper serves as an in-depth survey of text classification and machine learning, consolidating diverse aspects of the field into a single, comprehensive resource—a rarity in the current body of literature. Few studies have achieved such breadth, and this work aims to provide a unified perspective, offering a significant contribution to researchers and the academic community. The survey examines the evolution of machine learning in text categorization (TC), highlighting its transformative advantages over manual classification, such as enhanced accuracy, reduced labor, and adaptability across domains. It delves into various TC tasks and contrasts machine learning methodologies with knowledge engineering approaches, demonstrating the strengths and flexibility of data-driven techniques. Key applications of TC are explored, alongside an analysis of critical machine learning methods, including document representation techniques and dimensionality reduction strategies. Moreover, this study evaluates a range of text categorization models, identifies persistent challenges like class imbalance and overfitting, and investigates emerging trends shaping the future of the field. It discusses essential components such as document representation, classifier construction, and performance evaluation, offering a well-rounded understanding of the current state of TC. Importantly, this paper also provides clear research directions, emphasizing areas requiring further innovation, such as hybrid methodologies, explainable AI (XAI), and scalable approaches for low-resource languages. By bridging gaps in existing knowledge and suggesting actionable paths forward, this work positions itself as a vital resource for academics and industry practitioners, fostering deeper exploration and development in text classification.},
  issue = {2},
  langid = {english},
  file = {/home/dominik/Zotero/storage/HPZY6PWH/Allam et al. - 2025 - Text Classification How Machine Learning Is Revolutionizing Text Categorization.pdf}
}

@article{allegue2023,
  title = {{{SBM}}: {{A Smart Budget Manager}} in Banking Using Machine Learning, {{NLP}}, and {{NLU}}},
  shorttitle = {{{SBM}}},
  author = {Allegue, Sahar and Abdellatif, Takoua and El Abed, Houssem},
  date = {2023},
  journaltitle = {Concurrency and Computation: Practice and Experience},
  volume = {35},
  number = {11},
  pages = {Artikel e6673},
  issn = {1532-0634},
  doi = {10.1002/cpe.6673},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/cpe.6673},
  urldate = {2025-07-27},
  abstract = {New business models underpinned by new standards of openness, flexibility, and agility are arising in the banking sector. Therefore, banks have to establish new strategies to keep and to extend their client base, especially with the explosive growth of customers' data and interaction touch-points. Hence, banks and fintechs are in fierce competition to transform customers' data that incorporate their transactions into pertinent and significant knowledge for decision making. In this article, we present a novel system aimed toward solving a long-standing and challenging issue: obtaining classifiers to automatically categorize bank transactions for a Smart Budget Manager. We fit and test our system using real data. The strength of our system lies in the novel combination of incremental machine learning algorithms with a natural language understanding for a fine-grained categorization of bank transactions. Our system serves as a base layer for other advanced banking applications such as segmentation, next best offers and credit scoring. Our system is deployed in a real banking application of a Tunisian bank and has shown bank and customer's satisfaction.},
  langid = {english},
  file = {/home/dominik/Zotero/storage/MRN65SVS/Allegue et al. - 2023 - SBM A Smart Budget Manager in banking using machine learning, NLP, and NLU.pdf;/home/dominik/Zotero/storage/FSY5BH3E/cpe.html}
}

@article{ananda2020,
  title = {What Factors Drive the Adoption of Digital Banking? {{An}} Empirical Study from the Perspective of {{Omani}} Retail Banking},
  shorttitle = {What Factors Drive the Adoption of Digital Banking?},
  author = {Ananda, S. and Devesh, Sonal and Al Lawati, Anis Moosa},
  date = {2020-06-01},
  journaltitle = {Journal of Financial Services Marketing},
  shortjournal = {J Financ Serv Mark},
  volume = {25},
  number = {1},
  pages = {14--24},
  issn = {1479-1846},
  doi = {10.1057/s41264-020-00072-y},
  url = {https://doi.org/10.1057/s41264-020-00072-y},
  urldate = {2025-07-28},
  abstract = {This study aims to investigate the factors influencing the adoption of digital banking by retail banking customers. A theoretical model was developed based on an extended technology acceptance model to conceptualize the linkage among the factors impacting digital banking adoption. The primary data were acquired through a structured questionnaire from 200 customers. The multiple linear regression equation was used to analyse the relationship among six independent factors. The study revealed awareness, web features and perceived usefulness have significant positive influence on adoption of digital banking. The study is useful to plan and promote service model to enhance digital banking adoption.},
  langid = {english},
  file = {/home/dominik/Zotero/storage/C749TLQH/Ananda et al. - 2020 - What factors drive the adoption of digital banking An empirical study from the perspective of Omani.pdf}
}

@dataset{bis2025,
  title = {{{CPMI}} Cashless Payments Data},
  author = {{Bank for International Settlements}},
  date = {2025},
  url = {https://data.bis.org/},
  file = {/home/dominik/Zotero/storage/TFDTW8HW/data.html}
}

@report{capgemini2024,
  title = {World {{Payments Report}} 2025},
  author = {{Capgemini Research Institute}},
  date = {2024},
  number = {20},
  institution = {Capgemini},
  url = {https://www.capgemini.com/insights/research-library/world-payments-report/},
  urldate = {2025-07-28},
  abstract = {Get insights from World Payments Report 2025 on future of payments, including instant payments, open finance and strategies for enhancing global payments revenue.},
  langid = {american},
  file = {/home/dominik/Zotero/storage/WBAAG38F/2024 - World Payments Report 2025.pdf;/home/dominik/Zotero/storage/KTKXFT2A/world-payments-report.html}
}

@inproceedings{cater-steel2005,
  title = {Addressing the Challenges of Replications of Surveys in Software Engineering Research},
  booktitle = {2005 {{International Symposium}} on {{Empirical Software Engineering}}},
  author = {Cater-Steel, A. and Toleman, M. and Rout, T.},
  date = {2005-11},
  pages = {204--213},
  doi = {10.1109/ISESE.2005.1541829},
  url = {https://ieeexplore.ieee.org/abstract/document/1541829},
  urldate = {2025-07-20},
  abstract = {Surveys are a popular research tool often used in empirical software engineering studies. While researchers are urged to replicate existing surveys, such replication brings with it challenges. This paper presents a concrete example of a replication of a survey used to determine the extent of adoption of software development best practice. The study replicated a European survey which was adapted and administered in a different context of Australian software development organisations. As well as discussing problems encountered, this paper presents a set of recommendations formulated to overcome identified challenges. Implementation of the recommendations would strengthen the value and contribution of surveys to the body of knowledge of empirical software engineering research.},
  eventtitle = {2005 {{International Symposium}} on {{Empirical Software Engineering}}.},
  file = {/home/dominik/Zotero/storage/ZKS3HYFT/Cater-Steel et al. - 2005 - Addressing the challenges of replications of surveys in software engineering research.pdf}
}

@article{catolino2019,
  title = {Not All Bugs Are the Same: {{Understanding}}, Characterizing, and Classifying Bug Types},
  shorttitle = {Not All Bugs Are the Same},
  author = {Catolino, Gemma and Palomba, Fabio and Zaidman, Andy and Ferrucci, Filomena},
  date = {2019-06-01},
  journaltitle = {Journal of Systems and Software},
  shortjournal = {Journal of Systems and Software},
  volume = {152},
  pages = {165--181},
  issn = {0164-1212},
  doi = {10.1016/j.jss.2019.03.002},
  url = {https://www.sciencedirect.com/science/article/pii/S0164121219300536},
  urldate = {2025-07-20},
  abstract = {Modern version control systems, e.g., GitHub, include bug tracking mechanisms that developers can use to highlight the presence of bugs. This is done by means of bug reports, i.e., textual descriptions reporting the problem and the steps that led to a failure. In past and recent years, the research community deeply investigated methods for easing bug triage, that is, the process of assigning the fixing of a reported bug to the most qualified developer. Nevertheless, only a few studies have reported on how to support developers in the process of understanding the type of a reported bug, which is the first and most time-consuming step to perform before assigning a bug-fix operation. In this paper, we target this problem in two ways: first, we analyze 1280 bug reports of 119 popular projects belonging to three ecosystems such as Mozilla, Apache, and Eclipse, with the aim of building a taxonomy of the types of reported bugs; then, we devise and evaluate an automated classification model able to classify reported bugs according to the defined taxonomy. As a result, we found nine main common bug types over the considered systems. Moreover, our model achieves high F-Measure and AUC-ROC (64\% and 74\% on overall, respectively).},
  file = {/home/dominik/Zotero/storage/2WTJ6JWQ/Catolino et al. - 2019 - Not all bugs are the same Understanding, characterizing, and classifying bug types.pdf;/home/dominik/Zotero/storage/SMENAGEQ/S0164121219300536.html}
}

@article{cronin2017,
  title = {A Comparison of Rule-Based and Machine Learning Approaches for Classifying Patient Portal Messages},
  author = {Cronin, Robert M. and Fabbri, Daniel and Denny, Joshua C. and Rosenbloom, S. Trent and Jackson, Gretchen Purcell},
  date = {2017-09-01},
  journaltitle = {International Journal of Medical Informatics},
  shortjournal = {International Journal of Medical Informatics},
  volume = {105},
  pages = {110--120},
  issn = {1386-5056},
  doi = {10.1016/j.ijmedinf.2017.06.004},
  url = {https://www.sciencedirect.com/science/article/pii/S1386505617301818},
  urldate = {2025-07-28},
  abstract = {Objective Secure messaging through patient portals is an increasingly popular way that consumers interact with healthcare providers. The increasing burden of secure messaging can affect clinic staffing and workflows. Manual management of portal messages is costly and time consuming. Automated classification of portal messages could potentially expedite message triage and delivery of care. Materials and methods We developed automated patient portal message classifiers with rule-based and machine learning techniques using bag of words and natural language processing (NLP) approaches. To evaluate classifier performance, we used a gold standard of 3253 portal messages manually categorized using a taxonomy of communication types (i.e., main categories of informational, medical, logistical, social, and other communications, and subcategories including prescriptions, appointments, problems, tests, follow-up, contact information, and acknowledgement). We evaluated our classifiers’ accuracies in identifying individual communication types within portal messages with area under the receiver-operator curve (AUC). Portal messages often contain more than one type of communication. To predict all communication types within single messages, we used the Jaccard Index. We extracted the variables of importance for the random forest classifiers. Results The best performing approaches to classification for the major communication types were: logistic regression for medical communications (AUC: 0.899); basic (rule-based) for informational communications (AUC: 0.842); and random forests for social communications and logistical communications (AUCs: 0.875 and 0.925, respectively). The best performing classification approach of classifiers for individual communication subtypes was random forests for Logistical-Contact Information (AUC: 0.963). The Jaccard Indices by approach were: basic classifier, Jaccard Index: 0.674; Naïve Bayes, Jaccard Index: 0.799; random forests, Jaccard Index: 0.859; and logistic regression, Jaccard Index: 0.861. For medical communications, the most predictive variables were NLP concepts (e.g., Temporal\_Concept, which maps to ‘morning’, ‘evening’ and Idea\_or\_Concept which maps to ‘appointment’ and ‘refill’). For logistical communications, the most predictive variables contained similar numbers of NLP variables and words (e.g., Telephone mapping to ‘phone’, ‘insurance’). For social and informational communications, the most predictive variables were words (e.g., social: ‘thanks’, ‘much’, informational: ‘question’, ‘mean’). Conclusions This study applies automated classification methods to the content of patient portal messages and evaluates the application of NLP techniques on consumer communications in patient portal messages. We demonstrated that random forest and logistic regression approaches accurately classified the content of portal messages, although the best approach to classification varied by communication type. Words were the most predictive variables for classification of most communication types, although NLP variables were most predictive for medical communication types. As adoption of patient portals increases, automated techniques could assist in understanding and managing growing volumes of messages. Further work is needed to improve classification performance to potentially support message triage and answering.},
  file = {/home/dominik/Zotero/storage/D6EI9EC5/Cronin et al. - 2017 - A comparison of rule-based and machine learning approaches for classifying patient portal messages.pdf;/home/dominik/Zotero/storage/B28W2KM9/S1386505617301818.html}
}

@article{garcia-mendez2020,
  title = {Identifying {{Banking Transaction Descriptions}} via {{Support Vector Machine Short-Text Classification Based}} on a {{Specialized Labelled Corpus}}},
  author = {García-Méndez, Silvia and Fernández-Gavilanes, Milagros and Juncal-Martínez, Jonathan and González-Castaño, Francisco Javier and Seara, Óscar Barba},
  date = {2020},
  journaltitle = {IEEE Access},
  volume = {8},
  pages = {61642--61655},
  issn = {2169-3536},
  doi = {10.1109/ACCESS.2020.2983584},
  url = {https://ieeexplore.ieee.org/abstract/document/9047935},
  urldate = {2025-07-25},
  abstract = {Short texts are omnipresent in real-time news, social network commentaries, etc. Traditional text representation methods have been successfully applied to self-contained documents of medium size. However, information in short texts is often insufficient, due, for example, to the use of mnemonics, which makes them hard to classify. Therefore, the particularities of specific domains must be exploited. In this article we describe a novel system that combines Natural Language Processing techniques with Machine Learning algorithms to classify banking transaction descriptions for personal finance management, a problem that was not previously considered in the literature. We trained and tested that system on a labelled dataset with real customer transactions that will be available to other researchers on request. Motivated by existing solutions in spam detection, we also propose a short text similarity detector to reduce training set size based on the Jaccard distance. Experimental results with a two-stage classifier combining this detector with a SVM indicate a high accuracy in comparison with alternative approaches, taking into account complexity and computing time. Finally, we present a use case with a personal finance application, CoinScrap, which is available at Google Play and App Store.},
  file = {/home/dominik/Zotero/storage/Z4WGXJHB/García-Méndez et al. - 2020 - Identifying Banking Transaction Descriptions via Support Vector Machine Short-Text Classification Ba.pdf}
}

@online{jiang2024,
  title = {A {{Survey}} on {{Large Language Models}} for {{Code Generation}}},
  author = {Jiang, Juyong and Wang, Fan and Shen, Jiasi and Kim, Sungju and Kim, Sunghun},
  date = {2024},
  doi = {10.48550/arXiv.2406.00515},
  url = {http://arxiv.org/abs/2406.00515},
  abstract = {Large Language Models (LLMs) have garnered remarkable advancements across diverse code-related tasks, known as Code LLMs, particularly in code generation that generates source code with LLM from natural language descriptions. This burgeoning field has captured significant interest from both academic researchers and industry professionals due to its practical significance in software development, e.g., GitHub Copilot. Despite the active exploration of LLMs for a variety of code tasks, either from the perspective of natural language processing (NLP) or software engineering (SE) or both, there is a noticeable absence of a comprehensive and up-to-date literature review dedicated to LLM for code generation. In this survey, we aim to bridge this gap by providing a systematic literature review that serves as a valuable reference for researchers investigating the cutting-edge progress in LLMs for code generation. We introduce a taxonomy to categorize and discuss the recent developments in LLMs for code generation, covering aspects such as data curation, latest advances, performance evaluation, ethical implications, environmental impact, and real-world applications. In addition, we present a historical overview of the evolution of LLMs for code generation and offer an empirical comparison using the HumanEval, MBPP, and BigCodeBench benchmarks across various levels of difficulty and types of programming tasks to highlight the progressive enhancements in LLM capabilities for code generation. We identify critical challenges and promising opportunities regarding the gap between academia and practical development. Furthermore, we have established a dedicated resource GitHub page (https://github.com/juyongjiang/CodeLLMSurvey) to continuously document and disseminate the most recent advances in the field.},
  organization = {arXiv},
  pubstate = {prepublished},
  file = {/home/dominik/Zotero/storage/M795G357/Jiang et al. - 2024 - A Survey on Large Language Models for Code Generation.pdf;/home/dominik/Zotero/storage/9735EVTU/2406.html}
}

@article{khando2023,
  title = {The {{Emerging Technologies}} of {{Digital Payments}} and {{Associated Challenges}}: {{A Systematic Literature Review}}},
  shorttitle = {The {{Emerging Technologies}} of {{Digital Payments}} and {{Associated Challenges}}},
  author = {Khando, Khando and Islam, M. Sirajul and Gao, Shang},
  date = {2023-01},
  journaltitle = {Future Internet},
  volume = {15},
  number = {1},
  pages = {21},
  publisher = {Multidisciplinary Digital Publishing Institute},
  issn = {1999-5903},
  doi = {10.3390/fi15010021},
  url = {https://www.mdpi.com/1999-5903/15/1/21},
  urldate = {2025-07-28},
  abstract = {The interplay between finance and technology with the use of the internet triggered the emergence of digital payment technologies. Such technological innovation in the payment industry is the foundation for financial inclusion. However, despite the continuous progress and potential of moving the payment landscape towards digital payments and connecting the population to the ubiquitous digital environment, some critical issues need to be addressed to achieve a more harmonious inclusive and sustainable cashless society. The study aims to provide a comprehensive literature review on the emerging digital payment technologies and associated challenges. By systematically reviewing existing empirical studies, this study puts forward the state-of-the-art classification of digital payment technologies and presents four categories of digital payment technologies: card payment, e-payment,mobile payment and cryptocurrencies. Subsequently, the paper presents the key challenges in digital payment technologies categorized into broad themes: social, economic, technical, awareness and legal. The classification and categorization of payment technologies and associated challenges can be useful to both researchers and practitioners to understand, elucidate and develop a coherent digital payment strategy.},
  issue = {1},
  langid = {english},
  file = {/home/dominik/Zotero/storage/2U7P5TF2/Khando et al. - 2023 - The Emerging Technologies of Digital Payments and Associated Challenges A Systematic Literature Rev.pdf}
}

@article{kotios2022,
  title = {Deep Learning Enhancing Banking Services: A Hybrid Transaction Classification and Cash Flow Prediction Approach},
  shorttitle = {Deep Learning Enhancing Banking Services},
  author = {Kotios, Dimitrios and Makridis, Georgios and Fatouros, Georgios and Kyriazis, Dimosthenis},
  date = {2022-10-02},
  journaltitle = {Journal of Big Data},
  shortjournal = {J Big Data},
  volume = {9},
  number = {1},
  pages = {Artikel 100},
  issn = {2196-1115},
  doi = {10.1186/s40537-022-00651-x},
  url = {https://doi.org/10.1186/s40537-022-00651-x},
  urldate = {2025-07-27},
  abstract = {Small Medium Enterprises (SMEs) are vital to the global economy and all societies. However, they face a complex and challenging environment, as in most sectors they are lagging behind in their digital transformation. Banks, retaining a variety of data of their SME customers to perform their main activities, could offer a solution by leveraging all available data to provide a Business Financial Management (BFM) toolkit to their customers, providing value added services on top of their core business. In this direction, this paper revolves around the development of a smart, highly personalized hybrid transaction categorization model, interconnected with a cash flow prediction model based on Recurrent Neural Networks (RNNs). As the classification of transactions is of great significance, this research is extended towards explainable AI, where LIME and SHAP frameworks are utilized to interpret and illustrate the ML classification results. Our approach shows promising results on a real-world banking use case and acts as the foundation for the development of further BFM banking microservices, such as transaction fraud detection and budget monitoring.},
  langid = {english},
  keywords = {gebraucht},
  file = {/home/dominik/Zotero/storage/6ILMWF2H/Kotios et al. - 2022 - Deep learning enhancing banking services a hybrid transaction classification and cash flow predicti.pdf}
}

@article{li2022,
  title = {A {{Survey}} on {{Text Classification}}: {{From Traditional}} to {{Deep Learning}}},
  shorttitle = {A {{Survey}} on {{Text Classification}}},
  author = {Li, Qian and Peng, Hao and Li, Jianxin and Xia, Congying and Yang, Renyu and Sun, Lichao and Yu, Philip S. and He, Lifang},
  date = {2022-04-08},
  journaltitle = {ACM Trans. Intell. Syst. Technol.},
  volume = {13},
  number = {2},
  pages = {Artikel 31},
  issn = {2157-6904},
  doi = {10.1145/3495162},
  url = {https://dl.acm.org/doi/10.1145/3495162},
  urldate = {2025-07-27},
  abstract = {Text classification is the most fundamental and essential task in natural language processing. The last decade has seen a surge of research in this area due to the unprecedented success of deep learning. Numerous methods, datasets, and evaluation metrics have been proposed in the literature, raising the need for a comprehensive and updated survey. This paper fills the gap by reviewing the state-of-the-art approaches from 1961 to 2021, focusing on models from traditional models to deep learning. We create a taxonomy for text classification according to the text involved and the models used for feature extraction and classification. We then discuss each of these categories in detail, dealing with both the technical developments and benchmark datasets that support tests of predictions. A comprehensive comparison between different techniques, as well as identifying the pros and cons of various evaluation metrics are also provided in this survey. Finally, we conclude by summarizing key implications, future research directions, and the challenges facing the research area.},
  file = {/home/dominik/Zotero/storage/Q3XTIC86/Li et al. - 2022 - A Survey on Text Classification From Traditional to Deep Learning.pdf}
}

@article{minaee2021,
  title = {Deep {{Learning--based Text Classification}}: {{A Comprehensive Review}}},
  shorttitle = {Deep {{Learning--based Text Classification}}},
  author = {Minaee, Shervin and Kalchbrenner, Nal and Cambria, Erik and Nikzad, Narjes and Chenaghlu, Meysam and Gao, Jianfeng},
  date = {2021-04-17},
  journaltitle = {ACM Comput. Surv.},
  volume = {54},
  number = {3},
  pages = {Artikel 62},
  issn = {0360-0300},
  doi = {10.1145/3439726},
  url = {https://doi.org/10.1145/3439726},
  urldate = {2025-07-27},
  abstract = {Deep learning--based models have surpassed classical machine learning--based approaches in various text classification tasks, including sentiment analysis, news categorization, question answering, and natural language inference. In this article, we provide a comprehensive review of more than 150 deep learning--based models for text classification developed in recent years, and we discuss their technical contributions, similarities, and strengths. We also provide a summary of more than 40 popular datasets widely used for text classification. Finally, we provide a quantitative analysis of the performance of different deep learning models on popular benchmarks, and we discuss future research directions.},
  file = {/home/dominik/Zotero/storage/UPBE5NZF/Minaee et al. - 2021 - Deep Learning--based Text Classification A Comprehensive Review.pdf}
}

@online{paramesha2024,
  type = {SSRN Scholarly Paper},
  title = {Artificial {{Intelligence}}, {{Machine Learning}}, {{Deep Learning}}, and {{Blockchain}} in {{Financial}} and {{Banking Services}}: {{A Comprehensive Review}}},
  shorttitle = {Artificial {{Intelligence}}, {{Machine Learning}}, {{Deep Learning}}, and {{Blockchain}} in {{Financial}} and {{Banking Services}}},
  author = {Paramesha, Mallikarjuna and Rane, Nitin and Rane, Jayesh},
  date = {2024-06-06},
  number = {4855893},
  eprint = {4855893},
  eprinttype = {Social Science Research Network},
  location = {Rochester, NY},
  doi = {10.2139/ssrn.4855893},
  url = {https://papers.ssrn.com/abstract=4855893},
  urldate = {2025-07-27},
  abstract = {This research offers a thorough overview of the current research on artificial intelligence, machine learning, deep learning, and blockchain applications in the financial and banking industries, emphasizing the notable influence these technologies have had on spurring innovation and enhancing operational effectiveness. The research landscape is defined by key themes and trends through a detailed analysis of keyword co-occurrence and clusters in the study. The results highlight the important role of artificial intelligence in improving decision-making abilities, promoting innovation in financial markets, creating sophisticated trading strategies, and maintaining strong cybersecurity measures. Support vector machines and neural networks are more frequently utilized in predictive modeling, fraud detection, and portfolio management. Sophisticated data analysis tasks benefit from deep learning techniques like convolutional neural networks and long short-term memory networks, providing a more in-depth understanding of market trends and customer behaviors. Blockchain technology, known for its decentralized and transparent features, has become a crucial element in fintech advancements, guaranteeing secure and efficient transaction processing, ultimately building trust and minimizing the threat of fraud. The research also points out the merging of AI and blockchain, which is driving the creation of new financial products and services and encouraging digital transformation in the industry. Moreover, the research delves into the possibilities of new technologies such as quantum computing in solving intricate computational problems in the financial sector, including portfolio optimization, risk management, and cryptography. The research contributes by outlining key research topics, offering perspectives on various AI methods and uses, and proposing new research paths for exploring AI's integration in finance and banking.},
  langid = {english},
  pubstate = {prepublished},
  file = {/home/dominik/Zotero/storage/WW84S5KZ/Paramesha et al. - 2024 - Artificial Intelligence, Machine Learning, Deep Learning, and Blockchain in Financial and Banking Se.pdf}
}

@inproceedings{ta2023,
  title = {Specialized Text Classification: An Approach to Classifying {{Open Banking}} Transactions},
  shorttitle = {Specialized Text Classification},
  booktitle = {2023 {{IEEE}} 18th {{International Conference}} on {{Computer Science}} and {{Information Technologies}} ({{CSIT}})},
  author = {Ta, Duc Tuyen and Saad, Wajdi Ben and Oh, Ji Young},
  date = {2023-10-19},
  eprint = {2504.12319},
  eprinttype = {arXiv},
  eprintclass = {cs},
  pages = {1--4},
  doi = {10.1109/CSIT61576.2023.10324203},
  url = {http://arxiv.org/abs/2504.12319},
  urldate = {2025-07-27},
  abstract = {With the introduction of the PSD2 regulation in the EU which established the Open Banking framework, a new window of opportunities has opened for banks and fintechs to explore and enrich Bank transaction descriptions with the aim of building a better understanding of customer behavior, while using this understanding to prevent fraud, reduce risks and offer more competitive and tailored services. And although the usage of natural language processing models and techniques has seen an incredible progress in various applications and domains over the past few years, custom applications based on domain-specific text corpus remain unaddressed especially in the banking sector. In this paper, we introduce a language-based Open Banking transaction classification system with a focus on the french market and french language text. The system encompasses data collection, labeling, preprocessing, modeling, and evaluation stages. Unlike previous studies that focus on general classification approaches, this system is specifically tailored to address the challenges posed by training a language model with a specialized text corpus (Banking data in the French context). By incorporating language-specific techniques and domain knowledge, the proposed system demonstrates enhanced performance and efficiency compared to generic approaches.},
  file = {/home/dominik/Zotero/storage/XCPKCAUB/TA et al. - 2023 - Specialized text classification an approach to classifying Open Banking transactions.pdf;/home/dominik/Zotero/storage/CDQERL3I/2504.html}
}

@article{tambon2025,
  title = {Bugs in Large Language Models Generated Code: An Empirical Study},
  shorttitle = {Bugs in Large Language Models Generated Code},
  author = {Tambon, Florian and Moradi-Dakhel, Arghavan and Nikanjam, Amin and Khomh, Foutse and Desmarais, Michel C. and Antoniol, Giuliano},
  date = {2025-02-13},
  journaltitle = {Empirical Software Engineering},
  shortjournal = {Empir Software Eng},
  volume = {30},
  number = {3},
  pages = {Artikel 65},
  issn = {1573-7616},
  doi = {10.1007/s10664-025-10614-4},
  url = {https://doi.org/10.1007/s10664-025-10614-4},
  urldate = {2025-07-19},
  abstract = {Large Language Models (LLMs) for code have gained significant attention recently. They can generate code in different programming languages based on provided prompts, fulfilling a long-lasting dream in Software Engineering (SE), i.e., automatic code generation. Similar to human-written code, LLM-generated code is prone to bugs, and these bugs have not yet been thoroughly examined by the community. Given the increasing adoption of LLM-based code generation tools (e.g., GitHub Copilot) in SE activities, it is critical to understand the characteristics of bugs contained in code generated by LLMs. This paper examines samples of 333 bugs collected from code generated using three leading LLMs (i.e., CodeGen, PanGu-Coder, and Codex) and identifies the following 10 distinctive bug patterns: Misinterpretations, Syntax Error, Silly Mistake, Prompt-biased code, Missing Corner Case, Wrong Input Type, Hallucinated Object, Wrong Attribute, Incomplete Generation, and Non-Prompted Consideration. The bug patterns are presented in the form of a taxonomy. The identified bug patterns are validated using online surveys with over 50 LLM practitioners and researchers. The surveyed participants generally asserted the significance and prevalence of the bug patterns. Researchers and practitioners can leverage these findings to develop effective quality assurance techniques for LLM-generated code. This study sheds light on the distinctive characteristics of LLM-generated code.},
  langid = {english},
  file = {/home/dominik/Zotero/storage/FYJB6BJ5/Tambon et al. - 2025 - Bugs in large language models generated code an empirical study.pdf}
}

@inproceedings{yeung2025,
  title = {A Comparative Study of Rule-Based, Machine Learning and Large Language Model Approaches in Automated Writing Evaluation ({{AWE}})},
  booktitle = {Proceedings of the 15th {{International Learning Analytics}} and {{Knowledge Conference}}},
  author = {Yeung, Steven},
  date = {2025-03-03},
  series = {{{LAK}} '25},
  pages = {984--991},
  publisher = {Association for Computing Machinery},
  location = {New York, NY, USA},
  doi = {10.1145/3706468.3706566},
  url = {https://dl.acm.org/doi/10.1145/3706468.3706566},
  urldate = {2025-07-28},
  abstract = {Automated Writing Evaluation (AWE) tools have proved beneficial to writing development. Research on AWE methods is essential for improving tool performance and further comparative studies are needed as new methods emerge. This study examines the performance of several AWE approaches, comparing rule-based and statistical methods, machine learning (ML) models, and a large language model (LLM). These three AWE methods were applied to a representative sample of academic essays from the TOEFL11 dataset to compare their assessment performance. Results show that the selected LLM, GPT-4, outperformed the other two approaches in terms of QWK and Pearson’s correlation coefficient, while the Support Vector Machine (SVM) model in the ML approach had the highest accuracy and the lowest mean absolute error. This paper provides a detailed comparison of these three approaches and discusses implications for educational practice and future research around AWE.},
  isbn = {979-8-4007-0701-8},
  file = {/home/dominik/Zotero/storage/8N3HYGMZ/Yeung - 2025 - A comparative study of rule-based, machine learning and large language model approaches in automated.pdf}
}
